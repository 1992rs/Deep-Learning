{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcRuZARe0Ov9"
   },
   "source": [
    "## Reference Links - \n",
    "\n",
    "* **McCulloch-Pitts Neuron — Mankind’s First Mathematical Model Of A Biological Neuron -** https://towardsdatascience.com/mcculloch-pitts-model-5fdf65ac5dd1\n",
    "* **Perceptron Learning Algorithm: A Graphical Explanation Of Why It Works -** https://towardsdatascience.com/perceptron-learning-algorithm-d5db0deab975\n",
    "\n",
    "* **How neural networks build up their understanding of images -** https://distill.pub/2017/feature-visualization/\n",
    "\n",
    "* **TensorFlow Extended (TFX) is an end-to-end platform for deploying production ML pipelines -** https://www.tensorflow.org/tfx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IIstFzwcpJE"
   },
   "source": [
    "## Linear Regression using TensorFlow\n",
    "\n",
    "In this session, we will have a look at creating a linear regression model using tensorflow 2.0. Note that we already know the basics of linear regression and understand the implementation through sklearn. We will try to figure out how to do it using tensorflow tools that we have learnt.   \n",
    "\n",
    "\n",
    "<i>Note that to keep this exercise simple and focused on tensorflow and its relevant functions, we will make a very simple model with very basic preprocessing.</i> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykQXiPSPF_rf"
   },
   "source": [
    "#### Now, let us install the latest version of tensorflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvNefLdVoZNz"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvmX8Lp1GOSn"
   },
   "source": [
    "##### Check the version of the installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ry8J8nA4ocet",
    "outputId": "75b39cb2-6931-436e-d408-c971916c1927"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycFapGk6GTSi"
   },
   "source": [
    "Now Let us import out data and get it ready for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKt0pILMz_sn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "KGd9DbsKmQe2",
    "outputId": "4ccb061c-6e61-4ea9-ee1e-e7ce817b0b5e"
   },
   "outputs": [],
   "source": [
    "cars_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/usedcars.csv')\n",
    "cars_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nX1zbyI75RMi",
    "outputId": "bbf2144a-7ded-4520-d145-7639542da5aa"
   },
   "outputs": [],
   "source": [
    "cars_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "KuU03qQk1WfW",
    "outputId": "3be576f2-50ee-4482-aac0-c65ea0424c21"
   },
   "outputs": [],
   "source": [
    "#just some basic preprocessing\n",
    "cars_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "MDWmpQY9mWi4",
    "outputId": "9642f91a-70c5-4541-fa7e-b9ba1c2ae454"
   },
   "outputs": [],
   "source": [
    "#creating dummy variables for the categorical features\n",
    "cars_data = pd.get_dummies(cars_data)\n",
    "cars_data = cars_data.astype('float32') # we will need to convert the dataset to float in order to be able to convert it into tensors later.\n",
    "cars_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4YBIUaZ5zG4",
    "outputId": "9004fc2f-ada7-4770-b21d-ee70652e57b8"
   },
   "outputs": [],
   "source": [
    "#exploring column names\n",
    "cars_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhihQaPY6LfN"
   },
   "outputs": [],
   "source": [
    "#getting the features and labels and finally splitting the test and train data.\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = cars_data[['year','mileage', 'model_SE', 'model_SEL', 'model_SES',\n",
    "       'color_Black', 'color_Blue', 'color_Gold', 'color_Gray', 'color_Green',\n",
    "       'color_Red', 'color_Silver', 'color_White', 'color_Yellow',\n",
    "       'transmission_AUTO', 'transmission_MANUAL']]\n",
    "Y = cars_data['price']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJYtiMZfmiYx",
    "outputId": "68b3f046-2c1d-42ec-e4f7-4eb499c60e8a"
   },
   "outputs": [],
   "source": [
    "#let us scale the data as features are on different scales which might be a problem while modelling\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "# MinMaxScalar has been used here. You can go ahead and use the other scalars available and chcek the effect on the results.\n",
    "#fitting the transform on test and train separately\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHjzg7vF5z0T"
   },
   "outputs": [],
   "source": [
    "\n",
    "# let us now convert the data elements into tensors as we need tensors to be fed into different tensorflow based operations\n",
    "#X-train and X_test were converted to numpy arrays while transformations while the other two need to be transformed into numpy arrays.\n",
    "X_train=tf.convert_to_tensor(X_train)\n",
    "y_train=tf.convert_to_tensor(y_train.values)\n",
    "X_test=tf.convert_to_tensor(X_test)\n",
    "y_test=tf.convert_to_tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ZEQAKqs66EO",
    "outputId": "f9cb7672-0c6e-49aa-f264-d607d3b76cb3"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mecQN830IGb9"
   },
   "source": [
    "#### Let us try modelling now. We will use a few concepts covered in the practice exercise shared with the course material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVX-LUM8A-VW"
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "output_dim = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Let us initialize the weights and bias variables. \n",
    "weights = tf.Variable(tf.zeros(shape=(input_dim, output_dim), dtype= tf.float32))\n",
    "bias = tf.Variable(tf.ones(shape=(output_dim,), dtype= tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vh2blCxhBBtM",
    "outputId": "7bd542b4-2b1d-4997-8e7e-c9e396089946"
   },
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AoR9D90mBFQS",
    "outputId": "32cb519d-512e-4534-e467-1078747f408e"
   },
   "outputs": [],
   "source": [
    "bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uhitqoj2FH8U"
   },
   "outputs": [],
   "source": [
    "def predict(features):\n",
    "  return tf.matmul(features, weights) + bias # note that the matmul is matrix multiplication and is needed for calculating predictions\n",
    "\n",
    "def compute_loss(y_true, predictions):\n",
    "  return tf.reduce_mean(tf.square(y_true - predictions)) # mean square error\n",
    "\n",
    "# Let us now define a function to train the model. We will call the other functions in function definition.\n",
    "def train(x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = predict(x)\n",
    "    loss = compute_loss(y, predictions)\n",
    "    dloss_dw, dloss_db = tape.gradient(loss, [weights, bias]) #note that we can pass lists as well here.\n",
    "  weights.assign_sub(learning_rate * dloss_dw)\n",
    "  bias.assign_sub(learning_rate * dloss_db)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcVzQimxJJe2"
   },
   "source": [
    "#### Let us now, call the train function with 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWFBawhVoM4j",
    "outputId": "269baacb-d426-49ec-e0d7-311177a62424"
   },
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "  loss = train(X_train, y_train)\n",
    "  print('Epoch %d: Loss = %.4f' % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VHpA4MVu7Od",
    "outputId": "e36873c3-2f05-4d74-ffe7-65a0a606c8e7"
   },
   "outputs": [],
   "source": [
    "print('Final Weights after 50 epochs:')\n",
    "print('###############################################################################')\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uJAiiz7Yu9jP",
    "outputId": "a7915439-a98d-4ef5-ba2e-2ce7aa3d328d"
   },
   "outputs": [],
   "source": [
    "print('Final Bias after 50 epochs:')\n",
    "print('###############################################################################')\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJyQkdB70Gkj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdgve0a7Jwwq"
   },
   "source": [
    "#### Let us now test our model on the test data and predict on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyXnEJiyqNjv",
    "outputId": "706ec173-3da6-4079-de41-07aafa9182fe"
   },
   "outputs": [],
   "source": [
    "test_predictions = tf.matmul(X_test, weights) + bias\n",
    "print(compute_loss(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8xCBIesKGbY"
   },
   "source": [
    "We learnt creating a very simple linear regression model on cars data and predicted prices. \n",
    "\n",
    "Though, we could have done an extensive EDA and further improved the model but we have focused on tensorflow and its operations.\n",
    "\n",
    "<i>Happy Learning!</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mA4x01c3K9MO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "18. Session 18 - Deep Learning Week 1 - Intro to NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
